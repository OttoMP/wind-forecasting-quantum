{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pennylane as qml\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from quantum_neural_network import qnode_entangling, qnode_strong_entangling\n",
    "from stat_functions import quantitative_analysis, get_mean_left_right_error_interval, verify_distribution_wilcoxtest\n",
    "from experiments_main import carregar_tabela\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, n_layers):\n",
    "    plt.figure(figsize=(14,5), dpi=320, facecolor='w', edgecolor='k')\n",
    "    plt.title(f\"Loss for depth {n_layers}\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.plot(history.history['loss'], label=\"Loss/Epoch\")\n",
    "    plt.plot(history.history['val_loss'], label=\"Val Loss/Epoch\")\n",
    "    plt.xticks(range(0, len(history.history['loss'])+1, 5))\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction_versus_observed(n_layers, y_test, y_pred, mean_error_normal):\n",
    "    for i in range(y_test.shape[1]):\n",
    "        plt.figure(figsize=(20,5), dpi=320, facecolor='w', edgecolor='k')\n",
    "        plt.title(f\"Wind Speed Forecast for {i+1} hours ahead for {n_layers} layers\")\n",
    "        plt.xlabel(\"Samples\")\n",
    "        plt.ylabel(\"Wind Speed (m/s)\")\n",
    "        plt.plot(y_pred[:,i], label=\"Prediction\", color='blue')\n",
    "        plt.fill_between(range(y_pred.shape[0]), y_pred[:,i]-mean_error_normal[0,i], y_pred[:,i]+mean_error_normal[0,i], color='blue', alpha=0.05)\n",
    "        plt.plot(y_test[:,i], label=\"Original\", color='orange')\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev = 1\n",
    "data_folder = \"data\"\n",
    "city = \"mucuri\"\n",
    "height = \"150\"\n",
    "\n",
    "train_file = data_folder+\"/\"+city+\"/\"+height+\"/\"+\"train\"+height+\"_\"+city+\".txt\"\n",
    "X_all,y_all = carregar_tabela(train_file, prev)\n",
    "\n",
    "test_file = data_folder+\"/\"+city+\"/\"+height+\"/\"+\"prev\"+height+\"_\"+city+\".txt\"\n",
    "X_test,y_test = carregar_tabela(test_file,prev)\n",
    "\n",
    "n_features = X_all.shape[1]\n",
    "n_instances = X_all.shape[0]\n",
    "print(f\"There are {n_features} features and {n_instances} instances in Train set\")\n",
    "print(f\"There are {X_test.shape[1]} features and {X_test.shape[0]} instances in Test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_x = MinMaxScaler(feature_range=(-1, 1))\n",
    "#scaler_x = StandardScaler()\n",
    "X_all_scaled = scaler_x.fit_transform(X_all)\n",
    "\n",
    "X_test_scaled = scaler_x.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_all_scaled[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test_scaled[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting Train, Validation and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_all_scaled, y_all, test_size=1 - train_ratio)\n",
    "\n",
    "print(\"Len(Train):\",len(X_train))\n",
    "print(\"Len(Val):\"  ,len(X_val))\n",
    "print(\"Len(Test):\" ,len(X_test_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = n_features\n",
    "n_layers = 2\n",
    "print(f\"Circuit size: {n_qubits} qubits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_quantum_model(n_layers, n_qubits, strong_entangling=False):\n",
    "    print(f\"Training with depth {n_layers}\")\n",
    "    weight_shapes = {\"weights\": (n_layers,n_qubits,3)}\n",
    "\n",
    "    if strong_entangling:\n",
    "        q_layer = qml.qnn.KerasLayer(qnode_strong_entangling, weight_shapes, output_dim=n_qubits)\n",
    "    else:\n",
    "        q_layer = qml.qnn.KerasLayer(qnode_entangling, weight_shapes, output_dim=n_qubits)\n",
    "    activation=tf.keras.layers.Activation(tf.keras.activations.relu)\n",
    "    output_layer = tf.keras.layers.Dense(prev,kernel_initializer='normal')\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adamax(learning_rate=0.1)\n",
    "\n",
    "    model = tf.keras.models.Sequential([q_layer, activation, output_layer])\n",
    "    model.compile(loss=['mse'], optimizer=optimizer, metrics=['mae'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_quantum_model(n_layers, n_qubits)\n",
    "input_shape = (n_qubits,)\n",
    "model.build(input_shape)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es=EarlyStopping(monitor='val_loss', min_delta=0, patience=6, verbose=0, mode='auto', baseline=None, restore_best_weights=True)\n",
    "re=ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=0, mode='min', min_lr=0.00001)\n",
    "history_model = model.fit(X_train, y_train\n",
    "                        , epochs=50, batch_size=32\n",
    "                        , verbose=1\n",
    "                        , validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_model, n_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_scaled,verbose=1)\n",
    "mean_predictions, mean_error_normal, mean_error_left_normal, mean_error_right_normal = get_mean_left_right_error_interval(model, scaler_x, X_val, y_val, y_test, y_pred)\n",
    "plot_prediction_versus_observed(n_layers, y_test, y_pred, mean_error_normal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_analysis = quantitative_analysis(y_test, [y_pred])\n",
    "all_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_distribution_wilcoxtest(y_test[:,0],y_pred[:,0], 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating model with strong entangling and searching for statistical difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strong_model = create_quantum_model(n_layers, n_qubits, strong_entangling=True)\n",
    "input_shape = (n_qubits,)\n",
    "strong_model.build(input_shape)\n",
    "strong_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strong_history_model = strong_model.fit(X_train, y_train\n",
    "                        , epochs=50, batch_size=32\n",
    "                        , verbose=1\n",
    "                        , validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(strong_history_model, n_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strong_y_pred = strong_model.predict(X_test_scaled,verbose=1)\n",
    "mean_predictions, mean_error_normal, mean_error_left_normal, mean_error_right_normal = get_mean_left_right_error_interval(model, scaler_x, X_val, y_val, y_test, strong_y_pred)\n",
    "plot_prediction_versus_observed(n_layers, y_test, strong_y_pred, mean_error_normal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strong_analysis = quantitative_analysis(y_test, [strong_y_pred])\n",
    "strong_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_distribution_wilcoxtest(y_pred[:,0],strong_y_pred[:,0], 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating deeper model and searching for statistical difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = 6\n",
    "model2 = create_quantum_model(n_layers, n_qubits, strong_entangling=False)\n",
    "input_shape = (n_qubits,)\n",
    "model2.build(input_shape)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_model2 = model2.fit(X_train, y_train\n",
    "                        , epochs=50, batch_size=32\n",
    "                        , verbose=1\n",
    "                        , validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_model2, n_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = model2.predict(X_test_scaled,verbose=1)\n",
    "mean_predictions, mean_error_normal, mean_error_left_normal, mean_error_right_normal = get_mean_left_right_error_interval(model, scaler_x, X_val, y_val, y_test, y_pred2)\n",
    "plot_prediction_versus_observed(n_layers, y_test, y_pred2, mean_error_normal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_analysis2 = quantitative_analysis(y_test, [y_pred2])\n",
    "all_analysis2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_distribution_wilcoxtest(y_pred[:,0],y_pred2[:,0], 0.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
