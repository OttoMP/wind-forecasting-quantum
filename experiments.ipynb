{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pennylane as qml\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from quantum_neural_network import qnode_entangling, qnode_strong_entangling\n",
    "from stat_functions import quantitative_analysis, get_mean_left_right_error_interval\n",
    "from experiments_main import plot_history, plot_prediction_versus_observed, carregar_tabela\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MinMaxScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9 features and 549 instances in the train data\n",
      "There are 9 features and 193 instances in the test data\n"
     ]
    }
   ],
   "source": [
    "prev = 1\n",
    "\n",
    "train = \"data/train150_mucuri.txt\"\n",
    "X_all,y_all = carregar_tabela(train, prev)\n",
    "\n",
    "n_features = X_all.shape[1]\n",
    "n_instances = X_all.shape[0]\n",
    "print(f\"There are {n_features} features and {n_instances} instances in the train data\")\n",
    "\n",
    "test = \"data/prev150_mucuri.txt\"\n",
    "X_test,y_test = carregar_tabela(test,prev)\n",
    "\n",
    "n_features = X_test.shape[1]\n",
    "n_instances = X_test.shape[0]\n",
    "print(f\"There are {n_features} features and {n_instances} instances in the test data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dia</th>\n",
       "      <th>Mês</th>\n",
       "      <th>Ano</th>\n",
       "      <th>Hora</th>\n",
       "      <th>Velocidade</th>\n",
       "      <th>Direção</th>\n",
       "      <th>Temperatura</th>\n",
       "      <th>Umidade</th>\n",
       "      <th>Pressão</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>2015</td>\n",
       "      <td>14</td>\n",
       "      <td>13.012139</td>\n",
       "      <td>75.105481</td>\n",
       "      <td>27.516129</td>\n",
       "      <td>72.930636</td>\n",
       "      <td>1020.422601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>2015</td>\n",
       "      <td>15</td>\n",
       "      <td>12.726087</td>\n",
       "      <td>68.334332</td>\n",
       "      <td>27.238095</td>\n",
       "      <td>75.212121</td>\n",
       "      <td>1020.394348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>2015</td>\n",
       "      <td>16</td>\n",
       "      <td>12.081111</td>\n",
       "      <td>64.457865</td>\n",
       "      <td>27.105263</td>\n",
       "      <td>75.741379</td>\n",
       "      <td>1020.508333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>2015</td>\n",
       "      <td>17</td>\n",
       "      <td>11.647222</td>\n",
       "      <td>53.842100</td>\n",
       "      <td>26.305556</td>\n",
       "      <td>75.302632</td>\n",
       "      <td>1020.611000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>2015</td>\n",
       "      <td>18</td>\n",
       "      <td>11.064444</td>\n",
       "      <td>53.945279</td>\n",
       "      <td>25.464286</td>\n",
       "      <td>76.592593</td>\n",
       "      <td>1020.866500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dia  Mês   Ano  Hora  Velocidade     Direção  Temperatura   Umidade   \\\n",
       "0   30   11  2015    14    13.012139  75.105481    27.516129  72.930636   \n",
       "1   30   11  2015    15    12.726087  68.334332    27.238095  75.212121   \n",
       "2   30   11  2015    16    12.081111  64.457865    27.105263  75.741379   \n",
       "3   30   11  2015    17    11.647222  53.842100    26.305556  75.302632   \n",
       "4   30   11  2015    18    11.064444  53.945279    25.464286  76.592593   \n",
       "\n",
       "       Pressão  \n",
       "0  1020.422601  \n",
       "1  1020.394348  \n",
       "2  1020.508333  \n",
       "3  1020.611000  \n",
       "4  1020.866500  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.72608696],\n",
       "       [12.08111113],\n",
       "       [11.64722224],\n",
       "       [11.06444444],\n",
       "       [10.32444445]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_x = MinMaxScaler(feature_range=(-1, 1))\n",
    "X_all_scaled = scaler_x.fit_transform(X_all)\n",
    "\n",
    "X_test_scaled = scaler_x.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting Train, Validation and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len(Train): 439\n",
      "Len(Val): 110\n",
      "Len(Test): 193\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.8\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_all_scaled, y_all, test_size=1 - train_ratio)\n",
    "\n",
    "print(\"Len(Train):\",len(X_train))\n",
    "print(\"Len(Val):\"  ,len(X_val))\n",
    "print(\"Len(Test):\" ,len(X_test_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Circuit size: 9 qubits\n"
     ]
    }
   ],
   "source": [
    "n_qubits = n_features\n",
    "n_layers = 1\n",
    "print(f\"Circuit size: {n_qubits} qubits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_quantum_model(n_layers, n_qubits):\n",
    "    print(f\"Training with depth {n_layers}\")\n",
    "    weight_shapes = {\"weights\": (n_layers,n_qubits,3)}\n",
    "\n",
    "    input_layer = tf.keras.layers.Input(shape=(n_qubits,))\n",
    "    q_layer = qml.qnn.KerasLayer(qnode_strong_entangling, weight_shapes, output_dim=n_qubits)\n",
    "    activation=tf.keras.layers.Activation(tf.keras.activations.relu)\n",
    "    output_layer = tf.keras.layers.Dense(prev,kernel_initializer='normal')\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "\n",
    "    model = tf.keras.models.Sequential([input_layer, q_layer, activation, output_layer])\n",
    "    model.compile(loss=['mse'], optimizer=optimizer, metrics=['mae'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with depth 1\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 9)                 27        \n",
      "                                                                 \n",
      " activation (Activation)     (None, 9)                 0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37\n",
      "Trainable params: 37\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_quantum_model(n_layers, n_qubits)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es=EarlyStopping(monitor='val_loss', min_delta=0, patience=6, verbose=0, mode='auto', baseline=None, restore_best_weights=True)\n",
    "re=ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=0, mode='min', min_lr=0.00001)\n",
    "history_model = model.fit(X_train, y_train\n",
    "                        , epochs=50, batch_size=32\n",
    "                        , callbacks=[re]\n",
    "                        , verbose=0\n",
    "                        , validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_model, n_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_y_pred = []\n",
    "\n",
    "    #################\n",
    "    ### Loss Plot ###\n",
    "    #################\n",
    "\n",
    "    ##################\n",
    "    ### Prediction ###\n",
    "    ##################\n",
    "    y_pred = model.predict(X_test_scaled,verbose=0)\n",
    "    y_pred_normal = scaler_y.inverse_transform(y_pred)\n",
    "    list_y_pred.append(y_pred_normal)\n",
    "    mean_predictions, mean_error_normal, mean_error_left_normal, mean_error_right_normal = get_mean_left_right_error_interval(model, scaler_y, X_val, y_val, y_test, y_pred_normal)\n",
    "    plot_prediction_versus_observed(n_layers, y_test, y_pred_normal, mean_error_normal)\n",
    "    print(\"\\n#########\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
